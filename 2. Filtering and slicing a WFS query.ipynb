{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and slicing a WFS query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're starting a new notebook we need to read the file into listings again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "wfs_query = 'https://citydata.be.unsw.edu.au/geoserver/wfs?srsName=EPSG%3A4326&typename=geonode%3AInsideAirbnb_44_2015_17&outputFormat=csv&version=1.0.0&service=WFS&request=GetFeature'\n",
    "maxFeatures_param = '&maxFeatures=10'\n",
    "url = wfs_query + maxFeatures_param\n",
    "listings = pandas.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the columns themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listings.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on just the columns that look interesting. Our code will be more efficient if we refine our WFS query to access only the columns we need. This will reduce the size of the WFS response transferred over the internet, and also reduce the amount of data Python needs to keep in memory.\n",
    "\n",
    "We can do this by adding a filter. WFS filters are explained with examples by [Land Information New Zealand here](https://www.linz.govt.nz/data/linz-data-service/guides-and-documentation/wfs-filtering-by-attribute-or-feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refine our request to ask for just the City, ScrapeDate, PropertyID, HostID, Latitude, Longitude and Price. FID (feature identifier) will also be returned by default.\n",
    "\n",
    "To do this, add a `PropertyNames` parameter to the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PropertyName_param = '&PropertyName=City,ScrapeDate,PropertyID,HostID,Latitude,Longitude,Price'\n",
    "url = wfs_query + maxFeatures_param + PropertyName_param\n",
    "listings = pandas.read_csv(url)\n",
    "\n",
    "listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove the maxFeatures parameter so we are querying the full dataset, but if we do so, how much data will we get?\n",
    "\n",
    "We can check the number of results by adding the parameter `resultType=hits` to our request (without it the default is `resultType=results`).\n",
    "\n",
    "We also need to change the WFS version number from 1.0.0 to 1.1.0 because the resultType parameter was only introduced at this version of the [WFS spec](http://www.opengeospatial.org/standards/wfs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<https://citydata.be.unsw.edu.au/geoserver/wfs?typename=geonode%3AInsideAirbnb_44_2015_17&version=1.1.0&service=WFS&request=GetFeature&resultType=hits>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see the value for `numberOfFeatures` in the response to that URL? That's over a million records. Let's add a filter to look at just one city for now.\n",
    "\n",
    "The WFS `filter` parameter is specified in XML, which is a bit tricky to write by hand, especially in a one-line URL.\n",
    "\n",
    "Instead we'll use the non-standard [`cql_filter`](http://docs.geoserver.org/stable/en/user/tutorials/cql/cql_tutorial.html) parameter supported by Geoserver in which the filter is specified as a set of simple SQL-like constraints.\n",
    "\n",
    "We'll filter to select just one city, but first we need to know what cities are in the dataset. Unfortunately WFS does not by default support a request to list unique values of an attribute. We need to get the cities from the full dataset, then find the unique list in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PropertyName_param = '&PropertyName=City'\n",
    "url = wfs_query + PropertyName_param\n",
    "\n",
    "cities = pandas.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cities.City.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the parameter `cql_filter=City=\"Sydney\"` and count the number of records for Sydney:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<https://citydata.be.unsw.edu.au/geoserver/wfs?typename=geonode%3AInsideAirbnb_44_2015_17&version=1.1.0&service=WFS&request=GetFeature&cql_filter=City='Sydney'&resultType=hits>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That returned a more reasonable number of results.\n",
    "\n",
    "So now let's put together our request, still with maxFeatures for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PropertyName_param = '&PropertyName=City,ScrapeDate,PropertyID,HostID,Latitude,Longitude,Price'\n",
    "\n",
    "cql_filter_param = \"&cql_filter=City='Sydney'\" # use double quotes because the filter contains single quotes\n",
    "\n",
    "url = wfs_query + maxFeatures_param + PropertyName_param + cql_filter_param\n",
    "\n",
    "listings = pandas.read_csv(url)\n",
    "\n",
    "listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is called *‘Inside Airbnb’ listings for 44 cities, **2015-17*** so we should check if we have duplicate records from different scrape dates. Let's find unique values for scrape date as we did for cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PropertyName_param = '&PropertyName=ScrapeDate'\n",
    "\n",
    "url = wfs_query + PropertyName_param + cql_filter_param\n",
    "scrapedates = pandas.read_csv(url)\n",
    "\n",
    "scrapedates.ScrapeDate.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed for this Sydney data there are three separate scrapes: in 2015, 2016 and 2017. Let's select just the 2017 records by specifying this in the `cql_filter` query parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PropertyName_param = '&PropertyName=City,ScrapeDate,PropertyID,HostID,Latitude,Longitude,Price'\n",
    "\n",
    "cql_filter_param = \"&cql_filter=City='Sydney'+AND+ScrapeDate='2017-04-03T00:00:00'\"\n",
    "\n",
    "url = wfs_query + maxFeatures_param + PropertyName_param + cql_filter_param\n",
    "\n",
    "listings = pandas.read_csv(url)\n",
    "\n",
    "listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now continue from [Reading a slice of the whole dataset](3. Plotting your data.ipynb#filtered-whole-dataset) in the *Plot your data* notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
